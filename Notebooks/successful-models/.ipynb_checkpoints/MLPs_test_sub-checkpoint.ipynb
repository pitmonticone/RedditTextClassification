{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Challange: *Reddit Gender Text-Classification* (MLP) \n",
    "\n",
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Numpy & matplotlib for notebooks \n",
    "%pylab inline\n",
    "\n",
    "# Pandas for data analysis and manipulation \n",
    "import pandas as pd \n",
    "\n",
    "# Sklearn \n",
    "from sklearn.preprocessing import StandardScaler # to standardize features by removing the mean and scaling to unit variance (z=(x-u)/s)\n",
    "from sklearn.neural_network import MLPClassifier # Multi-layer Perceptron classifier which optimizes the log-loss function using LBFGS or sdg.\n",
    "from sklearn.model_selection import train_test_split # to split arrays or matrices into random train and test subsets\n",
    "from sklearn.model_selection import KFold # K-Folds cross-validator providing train/test indices to split data in train/test sets.\n",
    "from sklearn.decomposition import PCA, TruncatedSVD # Principal component analysis (PCA); dimensionality reduction using truncated SVD.\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB # Naive Bayes classifier for multinomial models\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Convert a collection of text documents to a matrix of token counts\n",
    "from sklearn.metrics import roc_auc_score as roc # Compute Area Under the Receiver Operating Characteristic Curve from prediction scores\n",
    "from sklearn.metrics import roc_curve, auc # Compute ROC; Compute Area Under the Curve (AUC) using the trapezoidal rule\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib # Data visualization\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as mpatches  \n",
    "\n",
    "# Seaborn\n",
    "import seaborn as sns # Statistical data visualization (based on matplotlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the training dataset, test dataset and target\n",
    "\n",
    "# Import the training dataset\n",
    "train_data = pd.read_csv(\"train_data.csv\", encoding=\"utf8\")\n",
    "\n",
    "# Import the test dataset\n",
    "test_data = pd.read_csv(\"test_data.csv\", encoding=\"utf8\")\n",
    "\n",
    "# Import the target\n",
    "target = pd.read_csv(\"train_target.csv\")\n",
    "\n",
    "# Create a dictionary of authors\n",
    "author_gender = {}\n",
    "for i in range(len(target)):\n",
    "    author_gender[target.author[i]] = target.gender[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of aggregated binary subreddits \n",
    "Xs = []\n",
    "# Create a list of genders\n",
    "y = []\n",
    "# Create a list of authors\n",
    "a = []\n",
    "\n",
    "# Populate the lists \n",
    "for author, group in train_data.groupby(\"author\"):\n",
    "    Xs.append(group.subreddit.str.cat(sep = \" \"))\n",
    "    y.append(author_gender[author])\n",
    "    a.append(author)\n",
    "    \n",
    "# Lower text in comments \n",
    "clean_train_subreddits = [xs.lower() for xs in Xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Definition & Training\n",
    "\n",
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CountVectorizer  \n",
    "vectorizer_ = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,\n",
    "                             binary=True\n",
    "                             ) #500\n",
    "# Train CountVectorizer  \n",
    "train_data_subreddits = vectorizer_.fit_transform(clean_train_subreddits).toarray()\n",
    "\n",
    "sum(train_data_subreddits[1])\n",
    "\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.60899191\n",
      "Validation score: 0.721461\n",
      "Iteration 2, loss = 0.49872264\n",
      "Validation score: 0.757991\n",
      "Iteration 3, loss = 0.41251641\n",
      "Validation score: 0.831050\n",
      "Iteration 4, loss = 0.35127469\n",
      "Validation score: 0.847032\n",
      "Iteration 5, loss = 0.31168246\n",
      "Validation score: 0.853881\n",
      "Iteration 6, loss = 0.28519341\n",
      "Validation score: 0.853881\n",
      "Iteration 7, loss = 0.26592054\n",
      "Validation score: 0.853881\n",
      "Iteration 8, loss = 0.25054187\n",
      "Validation score: 0.851598\n",
      "Iteration 9, loss = 0.23895993\n",
      "Validation score: 0.863014\n",
      "Iteration 10, loss = 0.22934773\n",
      "Validation score: 0.860731\n",
      "Iteration 11, loss = 0.22117200\n",
      "Validation score: 0.863014\n",
      "Iteration 12, loss = 0.21420363\n",
      "Validation score: 0.858447\n",
      "Iteration 13, loss = 0.20825104\n",
      "Validation score: 0.858447\n",
      "Iteration 14, loss = 0.20350864\n",
      "Validation score: 0.863014\n",
      "Iteration 15, loss = 0.19891814\n",
      "Validation score: 0.865297\n",
      "Iteration 16, loss = 0.19472937\n",
      "Validation score: 0.863014\n",
      "Iteration 17, loss = 0.19118028\n",
      "Validation score: 0.863014\n",
      "Iteration 18, loss = 0.18794875\n",
      "Validation score: 0.856164\n",
      "Iteration 19, loss = 0.18534473\n",
      "Validation score: 0.853881\n",
      "Iteration 20, loss = 0.18261292\n",
      "Validation score: 0.853881\n",
      "Iteration 21, loss = 0.18002646\n",
      "Validation score: 0.853881\n",
      "Iteration 22, loss = 0.17778487\n",
      "Validation score: 0.853881\n",
      "Iteration 23, loss = 0.17589230\n",
      "Validation score: 0.856164\n",
      "Iteration 24, loss = 0.17349652\n",
      "Validation score: 0.853881\n",
      "Iteration 25, loss = 0.17205280\n",
      "Validation score: 0.853881\n",
      "Iteration 26, loss = 0.17022238\n",
      "Validation score: 0.851598\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.8784\n",
      "Iteration 1, loss = 0.60750808\n",
      "Validation score: 0.721461\n",
      "Iteration 2, loss = 0.49830260\n",
      "Validation score: 0.769406\n",
      "Iteration 3, loss = 0.41293145\n",
      "Validation score: 0.842466\n",
      "Iteration 4, loss = 0.34957093\n",
      "Validation score: 0.851598\n",
      "Iteration 5, loss = 0.30809189\n",
      "Validation score: 0.856164\n",
      "Iteration 6, loss = 0.28077277\n",
      "Validation score: 0.856164\n",
      "Iteration 7, loss = 0.26060895\n",
      "Validation score: 0.851598\n",
      "Iteration 8, loss = 0.24557274\n",
      "Validation score: 0.853881\n",
      "Iteration 9, loss = 0.23347873\n",
      "Validation score: 0.853881\n",
      "Iteration 10, loss = 0.22381470\n",
      "Validation score: 0.860731\n",
      "Iteration 11, loss = 0.21589300\n",
      "Validation score: 0.856164\n",
      "Iteration 12, loss = 0.20873652\n",
      "Validation score: 0.849315\n",
      "Iteration 13, loss = 0.20282710\n",
      "Validation score: 0.849315\n",
      "Iteration 14, loss = 0.19776865\n",
      "Validation score: 0.847032\n",
      "Iteration 15, loss = 0.19310489\n",
      "Validation score: 0.840183\n",
      "Iteration 16, loss = 0.18921213\n",
      "Validation score: 0.847032\n",
      "Iteration 17, loss = 0.18585962\n",
      "Validation score: 0.840183\n",
      "Iteration 18, loss = 0.18251523\n",
      "Validation score: 0.842466\n",
      "Iteration 19, loss = 0.17958003\n",
      "Validation score: 0.844749\n",
      "Iteration 20, loss = 0.17681285\n",
      "Validation score: 0.849315\n",
      "Iteration 21, loss = 0.17448799\n",
      "Validation score: 0.844749\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.864\n",
      "Iteration 1, loss = 0.60935372\n",
      "Validation score: 0.726027\n",
      "Iteration 2, loss = 0.49940677\n",
      "Validation score: 0.776256\n",
      "Iteration 3, loss = 0.41377594\n",
      "Validation score: 0.837900\n",
      "Iteration 4, loss = 0.35214548\n",
      "Validation score: 0.853881\n",
      "Iteration 5, loss = 0.31143796\n",
      "Validation score: 0.863014\n",
      "Iteration 6, loss = 0.28450383\n",
      "Validation score: 0.860731\n",
      "Iteration 7, loss = 0.26501685\n",
      "Validation score: 0.865297\n",
      "Iteration 8, loss = 0.25084867\n",
      "Validation score: 0.860731\n",
      "Iteration 9, loss = 0.23935296\n",
      "Validation score: 0.865297\n",
      "Iteration 10, loss = 0.22973405\n",
      "Validation score: 0.856164\n",
      "Iteration 11, loss = 0.22218863\n",
      "Validation score: 0.858447\n",
      "Iteration 12, loss = 0.21555514\n",
      "Validation score: 0.863014\n",
      "Iteration 13, loss = 0.21035365\n",
      "Validation score: 0.865297\n",
      "Iteration 14, loss = 0.20500154\n",
      "Validation score: 0.863014\n",
      "Iteration 15, loss = 0.20169353\n",
      "Validation score: 0.863014\n",
      "Iteration 16, loss = 0.19734324\n",
      "Validation score: 0.863014\n",
      "Iteration 17, loss = 0.19412038\n",
      "Validation score: 0.860731\n",
      "Iteration 18, loss = 0.19079977\n",
      "Validation score: 0.863014\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.9024\n",
      "Iteration 1, loss = 0.60888472\n",
      "Validation score: 0.723744\n",
      "Iteration 2, loss = 0.49774647\n",
      "Validation score: 0.778539\n",
      "Iteration 3, loss = 0.41117221\n",
      "Validation score: 0.826484\n",
      "Iteration 4, loss = 0.34974789\n",
      "Validation score: 0.837900\n",
      "Iteration 5, loss = 0.31061804\n",
      "Validation score: 0.837900\n",
      "Iteration 6, loss = 0.28405253\n",
      "Validation score: 0.842466\n",
      "Iteration 7, loss = 0.26487805\n",
      "Validation score: 0.847032\n",
      "Iteration 8, loss = 0.25017126\n",
      "Validation score: 0.844749\n",
      "Iteration 9, loss = 0.23842462\n",
      "Validation score: 0.853881\n",
      "Iteration 10, loss = 0.22904704\n",
      "Validation score: 0.851598\n",
      "Iteration 11, loss = 0.22114694\n",
      "Validation score: 0.849315\n",
      "Iteration 12, loss = 0.21447913\n",
      "Validation score: 0.847032\n",
      "Iteration 13, loss = 0.20866007\n",
      "Validation score: 0.849315\n",
      "Iteration 14, loss = 0.20393676\n",
      "Validation score: 0.844749\n",
      "Iteration 15, loss = 0.19881584\n",
      "Validation score: 0.847032\n",
      "Iteration 16, loss = 0.19500684\n",
      "Validation score: 0.851598\n",
      "Iteration 17, loss = 0.19128735\n",
      "Validation score: 0.849315\n",
      "Iteration 18, loss = 0.18817582\n",
      "Validation score: 0.847032\n",
      "Iteration 19, loss = 0.18570832\n",
      "Validation score: 0.844749\n",
      "Iteration 20, loss = 0.18273839\n",
      "Validation score: 0.847032\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.888\n",
      "Iteration 1, loss = 0.60129876\n",
      "Validation score: 0.739726\n",
      "Iteration 2, loss = 0.49122468\n",
      "Validation score: 0.773973\n",
      "Iteration 3, loss = 0.40911741\n",
      "Validation score: 0.837900\n",
      "Iteration 4, loss = 0.34719446\n",
      "Validation score: 0.842466\n",
      "Iteration 5, loss = 0.30703346\n",
      "Validation score: 0.851598\n",
      "Iteration 6, loss = 0.27903920\n",
      "Validation score: 0.851598\n",
      "Iteration 7, loss = 0.25907534\n",
      "Validation score: 0.853881\n",
      "Iteration 8, loss = 0.24433209\n",
      "Validation score: 0.847032\n",
      "Iteration 9, loss = 0.23251707\n",
      "Validation score: 0.844749\n",
      "Iteration 10, loss = 0.22321332\n",
      "Validation score: 0.849315\n",
      "Iteration 11, loss = 0.21465808\n",
      "Validation score: 0.842466\n",
      "Iteration 12, loss = 0.20778483\n",
      "Validation score: 0.842466\n",
      "Iteration 13, loss = 0.20225149\n",
      "Validation score: 0.835616\n",
      "Iteration 14, loss = 0.19711005\n",
      "Validation score: 0.833333\n",
      "Iteration 15, loss = 0.19312440\n",
      "Validation score: 0.831050\n",
      "Iteration 16, loss = 0.18903634\n",
      "Validation score: 0.828767\n",
      "Iteration 17, loss = 0.18546709\n",
      "Validation score: 0.831050\n",
      "Iteration 18, loss = 0.18247423\n",
      "Validation score: 0.828767\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.8432\n",
      "Iteration 1, loss = 0.60100885\n",
      "Validation score: 0.746575\n",
      "Iteration 2, loss = 0.49138824\n",
      "Validation score: 0.773973\n",
      "Iteration 3, loss = 0.40743218\n",
      "Validation score: 0.858447\n",
      "Iteration 4, loss = 0.34709113\n",
      "Validation score: 0.860731\n",
      "Iteration 5, loss = 0.30676068\n",
      "Validation score: 0.878995\n",
      "Iteration 6, loss = 0.27881545\n",
      "Validation score: 0.883562\n",
      "Iteration 7, loss = 0.25895506\n",
      "Validation score: 0.874429\n",
      "Iteration 8, loss = 0.24378270\n",
      "Validation score: 0.878995\n",
      "Iteration 9, loss = 0.23122853\n",
      "Validation score: 0.881279\n",
      "Iteration 10, loss = 0.22174369\n",
      "Validation score: 0.874429\n",
      "Iteration 11, loss = 0.21380214\n",
      "Validation score: 0.876712\n",
      "Iteration 12, loss = 0.20636699\n",
      "Validation score: 0.876712\n",
      "Iteration 13, loss = 0.20016291\n",
      "Validation score: 0.876712\n",
      "Iteration 14, loss = 0.19497985\n",
      "Validation score: 0.872146\n",
      "Iteration 15, loss = 0.19036193\n",
      "Validation score: 0.867580\n",
      "Iteration 16, loss = 0.18617421\n",
      "Validation score: 0.874429\n",
      "Iteration 17, loss = 0.18240033\n",
      "Validation score: 0.858447\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.8112\n",
      "Iteration 1, loss = 0.60076667\n",
      "Validation score: 0.739726\n",
      "Iteration 2, loss = 0.49007926\n",
      "Validation score: 0.773973\n",
      "Iteration 3, loss = 0.41016393\n",
      "Validation score: 0.858447\n",
      "Iteration 4, loss = 0.34949097\n",
      "Validation score: 0.876712\n",
      "Iteration 5, loss = 0.30999993\n",
      "Validation score: 0.863014\n",
      "Iteration 6, loss = 0.28312345\n",
      "Validation score: 0.863014\n",
      "Iteration 7, loss = 0.26292323\n",
      "Validation score: 0.863014\n",
      "Iteration 8, loss = 0.24806538\n",
      "Validation score: 0.863014\n",
      "Iteration 9, loss = 0.23587813\n",
      "Validation score: 0.863014\n",
      "Iteration 10, loss = 0.22648998\n",
      "Validation score: 0.863014\n",
      "Iteration 11, loss = 0.21777460\n",
      "Validation score: 0.860731\n",
      "Iteration 12, loss = 0.21038720\n",
      "Validation score: 0.865297\n",
      "Iteration 13, loss = 0.20458593\n",
      "Validation score: 0.863014\n",
      "Iteration 14, loss = 0.19903486\n",
      "Validation score: 0.865297\n",
      "Iteration 15, loss = 0.19476249\n",
      "Validation score: 0.867580\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.8304\n",
      "Iteration 1, loss = 0.59960139\n",
      "Validation score: 0.739726\n",
      "Iteration 2, loss = 0.48753256\n",
      "Validation score: 0.764840\n",
      "Iteration 3, loss = 0.40625370\n",
      "Validation score: 0.847032\n",
      "Iteration 4, loss = 0.34617617\n",
      "Validation score: 0.853881\n",
      "Iteration 5, loss = 0.30565988\n",
      "Validation score: 0.851598\n",
      "Iteration 6, loss = 0.27897169\n",
      "Validation score: 0.851598\n",
      "Iteration 7, loss = 0.25986372\n",
      "Validation score: 0.849315\n",
      "Iteration 8, loss = 0.24483471\n",
      "Validation score: 0.858447\n",
      "Iteration 9, loss = 0.23301202\n",
      "Validation score: 0.858447\n",
      "Iteration 10, loss = 0.22343849\n",
      "Validation score: 0.860731\n",
      "Iteration 11, loss = 0.21486838\n",
      "Validation score: 0.865297\n",
      "Iteration 12, loss = 0.20828023\n",
      "Validation score: 0.865297\n",
      "Iteration 13, loss = 0.20242345\n",
      "Validation score: 0.865297\n",
      "Iteration 14, loss = 0.19729005\n",
      "Validation score: 0.865297\n",
      "Iteration 15, loss = 0.19336163\n",
      "Validation score: 0.860731\n",
      "Iteration 16, loss = 0.18906205\n",
      "Validation score: 0.865297\n",
      "Iteration 17, loss = 0.18535383\n",
      "Validation score: 0.867580\n",
      "Iteration 18, loss = 0.18251901\n",
      "Validation score: 0.869863\n",
      "Iteration 19, loss = 0.17961856\n",
      "Validation score: 0.867580\n",
      "Iteration 20, loss = 0.17694824\n",
      "Validation score: 0.869863\n",
      "Iteration 21, loss = 0.17434005\n",
      "Validation score: 0.869863\n",
      "Iteration 22, loss = 0.17308524\n",
      "Validation score: 0.874429\n",
      "Iteration 23, loss = 0.17053431\n",
      "Validation score: 0.869863\n",
      "Iteration 24, loss = 0.16832153\n",
      "Validation score: 0.872146\n",
      "Iteration 25, loss = 0.16681256\n",
      "Validation score: 0.863014\n",
      "Iteration 26, loss = 0.16504408\n",
      "Validation score: 0.869863\n",
      "Iteration 27, loss = 0.16340200\n",
      "Validation score: 0.869863\n",
      "Iteration 28, loss = 0.16189283\n",
      "Validation score: 0.863014\n",
      "Iteration 29, loss = 0.16090006\n",
      "Validation score: 0.865297\n",
      "Iteration 30, loss = 0.15908519\n",
      "Validation score: 0.865297\n",
      "Iteration 31, loss = 0.15739888\n",
      "Validation score: 0.863014\n",
      "Iteration 32, loss = 0.15672915\n",
      "Validation score: 0.863014\n",
      "Iteration 33, loss = 0.15552496\n",
      "Validation score: 0.860731\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.824\n"
     ]
    }
   ],
   "source": [
    "# Define MLP Classifier:\n",
    "## Activation function for the hidden layer: \"rectified linear unit function\"\n",
    "## Solver for weight optimization: \"stochastic gradient-based optimizer\"\n",
    "## Alpha: regularization parameter\n",
    "## Learning rate schedule for weight updates: \"gradually decreases the learning rate at each time step t using an inverse scaling exponent of power_t\"\n",
    "## Verbose: \"True\" in order to print progress messages to stdout.\n",
    "## Early stopping: \"True\" in order to use early stopping to terminate training when validation score is not improving. It automatically sets aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.\n",
    "\n",
    "mlpClf = MLPClassifier(activation= 'relu', solver = 'adam', \n",
    "                       alpha = 0.05, learning_rate = 'invscaling', verbose = True, \n",
    "                       early_stopping = True, max_iter = 400, random_state=0)\n",
    "\n",
    "        \n",
    "# K fold per la cross-validation\n",
    "kf = KFold(n_splits = 8)\n",
    "\n",
    "# Training and validation on all K folds\n",
    "for train_indices, test_indices in kf.split(X_train):\n",
    "    mlpClf.fit(X_train[train_indices], y_train[train_indices])\n",
    "    print(mlpClf.score(X_train[test_indices], y_train[test_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_test = []\n",
    "for author, group in test_data.groupby(\"author\"):\n",
    "    Xs_test.append(group.subreddit.str.cat(sep = \" \"))\n",
    "    \n",
    "Xs_test[1]\n",
    "\n",
    "clean_test_subreddits = [xs.lower() for xs in Xs_test]\n",
    "\n",
    "test_data_subreddits = vectorizer_.transform(clean_test_subreddits).toarray()\n",
    "\n",
    "y_score = mlpClf.predict_proba(test_data_subreddits)[:,1]\n",
    "\n",
    "len(y_score)\n",
    "\n",
    "np.save(\"y_testMLPs\",y_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
