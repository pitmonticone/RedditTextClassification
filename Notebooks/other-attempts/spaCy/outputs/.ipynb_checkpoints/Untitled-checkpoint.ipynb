{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencizer', 'trf_wordpiecer', 'trf_tok2vec']\n",
      "Loaded model 'en_trf_bertbaseuncased_lg'\n",
      "Loading IMDB data...\n",
      "Warning: Using test data. You should use development data for most experiments.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3cc27cbb85c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0meval_texts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0meval_cats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         ) = load_data_for_final_test(limit=n_texts)\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         (train_texts, train_cats), (eval_texts, eval_cats) = load_data(\n",
      "\u001b[1;32m<ipython-input-6-539d787a7f08>\u001b[0m in \u001b[0;36mload_data_for_final_test\u001b[1;34m(limit)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthinc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimdb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m     \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[0mtrain_texts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prepare_partition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[0mtest_texts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prepare_partition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: bad operand type for unary -: 'tuple'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import plac\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import thinc.extra.datasets\n",
    "import spacy\n",
    "import torch\n",
    "from spacy.util import minibatch\n",
    "import tqdm\n",
    "import unicodedata\n",
    "import wasabi\n",
    "from spacy_transformers.util import cyclic_triangular_rate\n",
    "\n",
    "\n",
    "# @plac.annotations(\n",
    "#     #model=(\"Model name\", \"positional\", None, str),\n",
    "#     input_dir=(\"Optional input directory\", \"option\", \"i\", Path),\n",
    "#     output_dir=(\"Optional output directory\", \"option\", \"o\", Path),\n",
    "#     #use_test=(\"Whether to use the actual test set\", \"flag\", \"E\"),\n",
    "#     batch_size=(\"Number of docs per batch\", \"option\", \"bs\", int),\n",
    "#     learn_rate=(\"Learning rate\", \"option\", \"lr\", float),\n",
    "#     max_wpb=(\"Max words per sub-batch\", \"option\", \"wpb\", int),\n",
    "#     n_texts=(\"Number of texts to train from\", \"option\", \"t\", int),\n",
    "#     n_iter=(\"Number of training epochs\", \"option\", \"n\", int),\n",
    "#     pos_label=(\"Positive label for evaluation\", \"option\", \"pl\", str),\n",
    "# )\n",
    "\n",
    "input_dir=None,\n",
    "output_dir=None,\n",
    "n_iter=5,\n",
    "n_texts=100,\n",
    "batch_size=8,\n",
    "learn_rate=2e-5,\n",
    "max_wpb=1000,\n",
    "use_test=False,\n",
    "pos_label=None,\n",
    "\n",
    "model = \"en_trf_bertbaseuncased_lg\"\n",
    "spacy.util.fix_random_seed(0)\n",
    "is_using_gpu = spacy.prefer_gpu()\n",
    "if is_using_gpu:\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "# if output_dir is not None:\n",
    "#     output_dir = Path(output_dir)\n",
    "#     if not output_dir.exists():\n",
    "#         output_dir.mkdir()\n",
    "\n",
    "nlp = spacy.load(model)\n",
    "print(nlp.pipe_names)\n",
    "print(f\"Loaded model '{model}'\")\n",
    "textcat = nlp.create_pipe(\n",
    "    \"trf_textcat\",\n",
    "    config={\"architecture\": \"softmax_last_hidden\", \"words_per_batch\": max_wpb},\n",
    ")\n",
    "#if input_dir is not None:\n",
    "if False:\n",
    "    train_texts, train_cats = read_inputs(input_dir / \"training.jsonl\")\n",
    "    eval_texts, eval_cats = read_inputs(input_dir / \"evaluation.jsonl\")\n",
    "    labels = set()\n",
    "    for cats in train_cats + eval_cats:\n",
    "        labels.update(cats)\n",
    "    # use the first label in the set as the positive label if one isn't\n",
    "    # provided\n",
    "    for label in sorted(labels):\n",
    "        if not pos_label:\n",
    "            pos_label = label\n",
    "        textcat.add_label(label)\n",
    "else:\n",
    "    # add label to text classifier\n",
    "    textcat.add_label(\"POSITIVE\")\n",
    "    textcat.add_label(\"NEGATIVE\")\n",
    "    if not pos_label:\n",
    "        pos_label = \"POSITIVE\"\n",
    "    # load the IMDB dataset\n",
    "    print(\"Loading IMDB data...\")\n",
    "    if use_test:\n",
    "        (train_texts, train_cats), (\n",
    "            eval_texts,\n",
    "            eval_cats,\n",
    "        ) = load_data_for_final_test(limit=n_texts)\n",
    "    else:\n",
    "        (train_texts, train_cats), (eval_texts, eval_cats) = load_data(\n",
    "            limit=n_texts\n",
    "        )\n",
    "\n",
    "print(\"Labels:\", textcat.labels)\n",
    "print(\"Positive label for evaluation:\", pos_label)\n",
    "nlp.add_pipe(textcat, last=True)\n",
    "print(f\"Using {len(train_texts)} training docs, {len(eval_texts)} evaluation\")\n",
    "split_training_by_sentence = False\n",
    "if split_training_by_sentence:\n",
    "    # If we're using a model that averages over sentence predictions (we are),\n",
    "    # there are some advantages to just labelling each sentence as an example.\n",
    "    # It means we can mix the sentences into different batches, so we can make\n",
    "    # more frequent updates. It also changes the loss somewhat, in a way that's\n",
    "    # not obviously better -- but it does seem to work well.\n",
    "    train_texts, train_cats = make_sentence_examples(nlp, train_texts, train_cats)\n",
    "    print(f\"Extracted {len(train_texts)} training sents\")\n",
    "# total_words = sum(len(text.split()) for text in train_texts)\n",
    "train_data = list(zip(train_texts, [{\"cats\": cats} for cats in train_cats]))\n",
    "# Initialize the TextCategorizer, and create an optimizer.\n",
    "optimizer = nlp.resume_training()\n",
    "optimizer.alpha = 0.001\n",
    "optimizer.trf_weight_decay = 0.005\n",
    "optimizer.L2 = 0.0\n",
    "learn_rates = cyclic_triangular_rate(\n",
    "    learn_rate / 3, learn_rate * 3, 2 * len(train_data) // batch_size\n",
    ")\n",
    "print(\"Training the model...\")\n",
    "print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
    "\n",
    "pbar = tqdm.tqdm(total=100, leave=False)\n",
    "results = []\n",
    "epoch = 0\n",
    "step = 0\n",
    "eval_every = 100\n",
    "patience = 3\n",
    "while True:\n",
    "    # Train and evaluate\n",
    "    losses = Counter()\n",
    "    random.shuffle(train_data)\n",
    "    batches = minibatch(train_data, size=batch_size)\n",
    "    for batch in batches:\n",
    "        optimizer.trf_lr = next(learn_rates)\n",
    "        texts, annotations = zip(*batch)\n",
    "        nlp.update(texts, annotations, sgd=optimizer, drop=0.1, losses=losses)\n",
    "        pbar.update(1)\n",
    "        if step and (step % eval_every) == 0:\n",
    "            pbar.close()\n",
    "            with nlp.use_params(optimizer.averages):\n",
    "                scores = evaluate(nlp, eval_texts, eval_cats, pos_label)\n",
    "            results.append((scores[\"textcat_f\"], step, epoch))\n",
    "            print(\n",
    "                \"{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\".format(\n",
    "                    losses[\"trf_textcat\"],\n",
    "                    scores[\"textcat_p\"],\n",
    "                    scores[\"textcat_r\"],\n",
    "                    scores[\"textcat_f\"],\n",
    "                )\n",
    "            )\n",
    "            pbar = tqdm.tqdm(total=eval_every, leave=False)\n",
    "        step += 1\n",
    "    epoch += 1\n",
    "    # Stop if no improvement in HP.patience checkpoints\n",
    "    if results:\n",
    "        best_score, best_step, best_epoch = max(results)\n",
    "        if ((step - best_step) // eval_every) >= patience:\n",
    "            break\n",
    "\n",
    "msg = wasabi.Printer()\n",
    "table_widths = [2, 4, 6]\n",
    "msg.info(f\"Best scoring checkpoints\")\n",
    "msg.row([\"Epoch\", \"Step\", \"Score\"], widths=table_widths)\n",
    "msg.row([\"-\" * width for width in table_widths])\n",
    "for score, step, epoch in sorted(results, reverse=True)[:10]:\n",
    "    msg.row([epoch, step, \"%.2f\" % (score * 100)], widths=table_widths)\n",
    "\n",
    "# Test the trained model\n",
    "test_text = eval_texts[0]\n",
    "doc = nlp(test_text)\n",
    "print(test_text, doc.cats)\n",
    "\n",
    "if output_dir is not None:\n",
    "    nlp.to_disk(output_dir)\n",
    "    print(\"Saved model to\", output_dir)\n",
    "    # test the saved model\n",
    "    print(\"Loading from\", output_dir)\n",
    "    nlp2 = spacy.load(output_dir)\n",
    "    doc2 = nlp2(test_text)\n",
    "    print(test_text, doc2.cats)\n",
    "\n",
    "\n",
    "def read_inputs(input_path):\n",
    "    texts = []\n",
    "    cats = []\n",
    "    with input_path.open(mode=\"r\") as file_:\n",
    "        for line in file_:\n",
    "            text, gold = json.loads(line)\n",
    "            text = preprocess_text(text)\n",
    "            texts.append(text)\n",
    "            cats.append(gold[\"cats\"])\n",
    "    return texts, cats\n",
    "\n",
    "\n",
    "def make_sentence_examples(nlp, texts, labels):\n",
    "    \"\"\"Treat each sentence of the document as an instance, using the doc labels.\"\"\"\n",
    "    sents = []\n",
    "    sent_cats = []\n",
    "    for text, cats in zip(texts, labels):\n",
    "        doc = nlp.make_doc(text)\n",
    "        doc = nlp.get_pipe(\"sentencizer\")(doc)\n",
    "        for sent in doc.sents:\n",
    "            sents.append(sent.text)\n",
    "            sent_cats.append(cats)\n",
    "    return sents, sent_cats\n",
    "\n",
    "\n",
    "white_re = re.compile(r\"\\s\\s+\")\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.replace(\"<s>\", \"<open-s-tag>\")\n",
    "    text = text.replace(\"</s>\", \"<close-s-tag>\")\n",
    "    text = white_re.sub(\" \", text).strip()\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFD\", text) if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "\n",
    "\n",
    "def load_data(*, limit=0, dev_size=2000):\n",
    "    \"\"\"Load data from the IMDB dataset, splitting off a held-out set.\"\"\"\n",
    "    if limit != 0:\n",
    "        limit += dev_size\n",
    "    assert dev_size != 0\n",
    "    train_data, _ = thinc.extra.datasets.imdb(limit=limit)\n",
    "    assert len(train_data) > dev_size\n",
    "    random.shuffle(train_data)\n",
    "    dev_data = train_data[:dev_size]\n",
    "    train_data = train_data[dev_size:]\n",
    "    train_texts, train_labels = _prepare_partition(train_data, preprocess=False)\n",
    "    dev_texts, dev_labels = _prepare_partition(dev_data, preprocess=False)\n",
    "    return (train_texts, train_labels), (dev_texts, dev_labels)\n",
    "\n",
    "\n",
    "def load_data_for_final_test(*, limit=0):\n",
    "    print(\n",
    "        \"Warning: Using test data. You should use development data for most experiments.\"\n",
    "    )\n",
    "    train_data, test_data = thinc.extra.datasets.imdb()\n",
    "    random.shuffle(train_data)\n",
    "    print(\"here\")\n",
    "    u = len(train_data) - limit\n",
    "    train_data = train_data[ u :]  # train_data[-limit:]\n",
    "    train_texts, train_labels = _prepare_partition(train_data)\n",
    "    test_texts, test_labels = _prepare_partition(test_data)\n",
    "    return (train_texts, train_labels), (test_texts, test_labels)\n",
    "\n",
    "\n",
    "def _prepare_partition(text_label_tuples, *, preprocess=False):\n",
    "    texts, labels = zip(*text_label_tuples)\n",
    "    if preprocess:\n",
    "        # Preprocessing can mask errors in our handling of noisy text, so\n",
    "        # we don't want to do it by default\n",
    "        texts = [preprocess_text(text) for text in texts]\n",
    "    cats = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)} for y in labels]\n",
    "    return texts, cats\n",
    "\n",
    "\n",
    "def evaluate(nlp, texts, cats, pos_label):\n",
    "    tp = 0.0  # True positives\n",
    "    fp = 0.0  # False positives\n",
    "    fn = 0.0  # False negatives\n",
    "    tn = 0.0  # True negatives\n",
    "    total_words = sum(len(text.split()) for text in texts)\n",
    "    with tqdm.tqdm(total=total_words, leave=False) as pbar:\n",
    "        for i, doc in enumerate(nlp.pipe(texts, batch_size=8)):\n",
    "            gold = cats[i]\n",
    "            for label, score in doc.cats.items():\n",
    "                if label not in gold:\n",
    "                    continue\n",
    "                if label != pos_label:\n",
    "                    continue\n",
    "                if score >= 0.5 and gold[label] >= 0.5:\n",
    "                    tp += 1.0\n",
    "                elif score >= 0.5 and gold[label] < 0.5:\n",
    "                    fp += 1.0\n",
    "                elif score < 0.5 and gold[label] < 0.5:\n",
    "                    tn += 1\n",
    "                elif score < 0.5 and gold[label] >= 0.5:\n",
    "                    fn += 1\n",
    "            pbar.update(len(doc.text.split()))\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    if (precision + recall) == 0:\n",
    "        f_score = 0.0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score}\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     plac.call(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myEnv]",
   "language": "python",
   "name": "conda-env-myEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
