{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2v\n",
    "\n",
    "A classification of W2v spaCy vectors, using scikit MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # For scaling\n",
    "from sklearn.model_selection import train_test_split # for creating valid set and train set \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "y = np.load(\"targets.npy\").tolist()\n",
    "files = listdir(\"npy5000/\")\n",
    "files = [f for f in files if f == \"lPunctNumStopLemOovAgg.npy\"]\n",
    "for f in files:\n",
    "    for i in range(1):\n",
    "        X = np.load(\"../input/mydata/npy5000/\"+f)\n",
    "        i = 75\n",
    "        pca = PCA(i)\n",
    "        pca.fit(X)\n",
    "        U = pca.transform(X)\n",
    "        U = U.tolist()\n",
    "        df = pd.DataFrame({\"vect\": U, \"gender\": y})\n",
    "    # unbalnced \n",
    "        seed = 100\n",
    "        split = math.floor(len(df)*0.8)\n",
    "        train_df = df.sample(split, random_state = 100)\n",
    "        test_df = df.drop(train_df.index)\n",
    "        x_train = np.array(train_df[\"vect\"].tolist())\n",
    "        print(\"x_train.shape = \", x_train.shape)\n",
    "       #print(\"x_train[0] = \", x_train[0])\n",
    "        x_validation = np.array(test_df[\"vect\"].tolist())\n",
    "        print(\"x_validation.shape = \", x_validation.shape)\n",
    "        y_train = np.array(train_df[\"gender\"].tolist())\n",
    "        print(\"y_train.shape = \", y_train.shape)\n",
    "        y_validation = np.array(test_df[\"gender\"].tolist())\n",
    "        print(\"y_validation.shape = \", y_validation.shape)  \n",
    "\n",
    "# end of unbalanced\n",
    "        \n",
    "    # balanced part\n",
    "#         U_m = df.loc[df[\"gender\"] == 0, :]\n",
    "#         U_f = df.loc[df[\"gender\"] == 1, :]\n",
    "\n",
    "#         split = math.floor(len(U_f)*0.8)\n",
    "#         print(\"split = \",split)\n",
    "\n",
    "#         seed  = 100\n",
    "\n",
    "#         train_data_sample_m =  U_m.sample(n = split, random_state = seed)\n",
    "#         train_vects_m =train_data_sample_m[\"vect\"].tolist()\n",
    "#         test_data_sample_m = U_m.drop(train_data_sample_m.index)\n",
    "#         #test_data_sample_m = test_data_sample_m.reset_index() \n",
    "#         test_vects_m = test_data_sample_m[\"vect\"].tolist()\n",
    "\n",
    "#         train_data_sample_f =  U_f.sample(n = split, random_state = seed)\n",
    "#         train_vects_f = train_data_sample_f[\"vect\"].tolist()\n",
    "#         test_data_sample_f = U_f.drop(train_data_sample_f.index)\n",
    "#         #test_data_sample_f = test_data_sample_f.reset_index() \n",
    "#         test_vects_f = test_data_sample_f[\"vect\"].tolist()\n",
    "\n",
    "#         train_vects = train_vects_m + train_vects_f\n",
    "#         test_vects = test_vects_m + test_vects_f\n",
    "\n",
    "#         train_labels = [0 for i in range(split)] + [1 for i in range(split)]\n",
    "#         test_labels = [0 for i in range(len(U_m)-split)] + [1 for i in range(len(U_f)-split)]\n",
    "#         x_train = np.array(train_vects)\n",
    "#         print(\"x_train.shape = \", x_train.shape)\n",
    "#         #print(\"x_train[0] = \", x_train[0])\n",
    "#         x_validation = np.array(test_vects)\n",
    "#         print(\"x_validation.shape = \", x_validation.shape)\n",
    "#         y_train = np.array(train_labels)\n",
    "#         print(\"y_train.shape = \", y_train.shape)\n",
    "#         y_validation = np.array(test_labels)\n",
    "#         print(\"y_validation.shape = \", y_validation.shape)\n",
    "#         x_train, y_train = shuffle(x_train, y_train, random_state = 0)\n",
    "    # end of balanced\n",
    "    \n",
    "    \n",
    "    # model\n",
    "        mlpClf = MLPClassifier(solver = 'adam', activation= 'relu' ,alpha = 0.02, verbose = False, early_stopping = True,\n",
    "                             learning_rate = 'invscaling', max_iter = 400)\n",
    "\n",
    "    # Cross validation - 10 Fold \n",
    "        kf = KFold(n_splits = 10)\n",
    "\n",
    "        for train_indices, test_indices in kf.split(x_train):\n",
    "            mlpClf.fit(x_train[train_indices], y_train[train_indices])\n",
    "            print(mlpClf.score(x_train[test_indices], y_train[test_indices]))\n",
    "        y_score = mlpClf.predict_proba(x_validation)[:,1]\n",
    "        fpr, tpr, thresholds = roc_curve(y_validation, y_score)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc = str(roc_auc)\n",
    "        name = f.replace(\".npy\",\"\")+\"_\"+str(i)\n",
    "        print(name+\" : \"+str(roc_auc))\n",
    "    #         with open( \"spacyW2vMlp\" + \".txt\", \"a\") as file: #name\n",
    "    #             file.write(\"\\t pca_\" +str(i)+ \" : \" + roc+\"\\n\")\n",
    "    #             file.close()\n",
    "\n",
    "\n",
    "# df_res = pd.DataFrame({\"pred_y\": y_score, \"true_y\":y_validation})\n",
    "# df_res.to_csv (r'../working/W2v.csv', index = False, header=True)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### balanced results different pca's\n",
    "\n",
    "split =  1079<br>\n",
    "x_train.shape =  (2158, 10)<br>\n",
    "x_validation.shape =  (2842, 10)<br>\n",
    "y_train.shape =  (2158,)<br>\n",
    "y_validation.shape =  (2842,)<br>\n",
    "\n",
    "lPunctNumStopLemOovAgg_10 : 0.7773587350959046 <br>\n",
    "lPunctNumStopLemOovAgg_20 : 0.7794985887909682 <br>\n",
    "lPunctNumStopLemOovAgg_30 : 0.8106258280052993 <br>\n",
    "lPunctNumStopLemOovAgg_40 : 0.8099159034617822<br>\n",
    "lPunctNumStopLemOovAgg_50 : 0.8292624272795345<br>\n",
    "lPunctNumStopLemOovAgg_60 : 0.8135677668337078<br>\n",
    "lPunctNumStopLemOovAgg_70 : 0.8236233511894476<br>\n",
    "lPunctNumStopLemOovAgg_75 : 0.8321510857669489<br>\n",
    "lPunctNumStopLemOovAgg_80 : 0.8347517424111515<br>\n",
    "lPunctNumStopLemOovAgg_85 : 0.7923204308507575<br>\n",
    "lPunctNumStopLemOovAgg_90 : 0.8280326594090203<br>\n",
    "lPunctNumStopLemOovAgg_100 : 0.8135144864927135<br>\n",
    "lPunctNumStopLemOovAgg_110 : 0.7994311963596568<br>\n",
    "lPunctNumStopLemOovAgg_120 : 0.8126332008524854<br>\n",
    "lPunctNumStopLemOovAgg_130 : 0.7794049881919244<br>\n",
    "lPunctNumStopLemOovAgg_140 : 0.8027504176026727<br>\n",
    "lPunctNumStopLemOovAgg_150 : 0.7867101549449917<br>\n",
    "lPunctNumStopLemOovAgg_160 : 0.8010440066816429<br>\n",
    "lPunctNumStopLemOovAgg_165 : 0.8039686653994587<br>\n",
    "lPunctNumStopLemOovAgg_170 : 0.8058219572605264<br>\n",
    "lPunctNumStopLemOovAgg_180 : 0.8310192385231266<br>\n",
    "lPunctNumStopLemOovAgg_190 : 0.8154628189620413<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "df_res = pd.DataFrame({\"pred_y\": y_score, \"true_y\":y_validation})\n",
    "df_res.to_csv (r'../working/W2v_bal.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
