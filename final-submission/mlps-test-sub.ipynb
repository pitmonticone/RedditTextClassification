{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Challange: *Reddit Gender Text-Classification* (MLP) \n",
    "\n",
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Numpy & matplotlib for notebooks \n",
    "%pylab inline\n",
    "\n",
    "# Pandas for data analysis and manipulation \n",
    "import pandas as pd \n",
    "\n",
    "# Sklearn \n",
    "from sklearn.preprocessing import StandardScaler # to standardize features by removing the mean and scaling to unit variance (z=(x-u)/s)\n",
    "from sklearn.neural_network import MLPClassifier # Multi-layer Perceptron classifier which optimizes the log-loss function using LBFGS or sdg.\n",
    "from sklearn.model_selection import train_test_split # to split arrays or matrices into random train and test subsets\n",
    "from sklearn.model_selection import KFold # K-Folds cross-validator providing train/test indices to split data in train/test sets.\n",
    "from sklearn.decomposition import PCA, TruncatedSVD # Principal component analysis (PCA); dimensionality reduction using truncated SVD.\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB # Naive Bayes classifier for multinomial models\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Convert a collection of text documents to a matrix of token counts\n",
    "from sklearn.metrics import roc_auc_score as roc # Compute Area Under the Receiver Operating Characteristic Curve from prediction scores\n",
    "from sklearn.metrics import roc_curve, auc # Compute ROC; Compute Area Under the Curve (AUC) using the trapezoidal rule\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib # Data visualization\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as mpatches  \n",
    "\n",
    "# Seaborn\n",
    "import seaborn as sns # Statistical data visualization (based on matplotlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the training dataset, test dataset and target\n",
    "\n",
    "# Import the training dataset\n",
    "train_data = pd.read_csv(\"../input/dataset/train_data.csv\", encoding=\"utf8\")\n",
    "\n",
    "# Import the test dataset\n",
    "test_data = pd.read_csv(\"../input/dataset/test_data.csv\", encoding=\"utf8\")\n",
    "\n",
    "# Import the target\n",
    "target = pd.read_csv(\"../input/dataset/train_target.csv\")\n",
    "\n",
    "# Create a dictionary of authors\n",
    "author_gender = {}\n",
    "for i in range(len(target)):\n",
    "    author_gender[target.author[i]] = target.gender[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of aggregated binary subreddits \n",
    "Xs = []\n",
    "# Create a list of genders\n",
    "y = []\n",
    "# Create a list of authors\n",
    "a = []\n",
    "\n",
    "# Populate the lists \n",
    "for author, group in train_data.groupby(\"author\"):\n",
    "    Xs.append(group.subreddit.str.cat(sep = \" \"))\n",
    "    y.append(author_gender[author])\n",
    "    a.append(author)\n",
    "    \n",
    "# Lower text in comments \n",
    "clean_train_subreddits = [xs.lower() for xs in Xs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Definition & Training\n",
    "\n",
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CountVectorizer  \n",
    "vectorizer_ = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,\n",
    "                             binary=True\n",
    "                             ) #500\n",
    "# Train CountVectorizer  \n",
    "train_data_subreddits = vectorizer_.fit_transform(clean_train_subreddits).toarray()\n",
    "\n",
    "sum(train_data_subreddits[1])\n",
    "\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.59613047\n",
      "Validation score: 0.734000\n",
      "Iteration 2, loss = 0.47953355\n",
      "Validation score: 0.814000\n",
      "Iteration 3, loss = 0.39179575\n",
      "Validation score: 0.864000\n",
      "Iteration 4, loss = 0.33398556\n",
      "Validation score: 0.870000\n",
      "Iteration 5, loss = 0.29788160\n",
      "Validation score: 0.860000\n",
      "Iteration 6, loss = 0.27413851\n",
      "Validation score: 0.858000\n",
      "Iteration 7, loss = 0.25758394\n",
      "Validation score: 0.856000\n",
      "Iteration 8, loss = 0.24291078\n",
      "Validation score: 0.858000\n",
      "Iteration 9, loss = 0.23275980\n",
      "Validation score: 0.864000\n",
      "Iteration 10, loss = 0.22383857\n",
      "Validation score: 0.860000\n",
      "Iteration 11, loss = 0.21650923\n",
      "Validation score: 0.860000\n",
      "Iteration 12, loss = 0.21024405\n",
      "Validation score: 0.850000\n",
      "Iteration 13, loss = 0.20492907\n",
      "Validation score: 0.850000\n",
      "Iteration 14, loss = 0.20017990\n",
      "Validation score: 0.848000\n",
      "Iteration 15, loss = 0.19573230\n",
      "Validation score: 0.850000\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='invscaling',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=400,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define MLP Classifier:\n",
    "## Activation function for the hidden layer: \"rectified linear unit function\"\n",
    "## Solver for weight optimization: \"stochastic gradient-based optimizer\"\n",
    "## Alpha: regularization parameter\n",
    "## Learning rate schedule for weight updates: \"gradually decreases the learning rate at each time step t using an inverse scaling exponent of power_t\"\n",
    "## Verbose: \"True\" in order to print progress messages to stdout.\n",
    "## Early stopping: \"True\" in order to use early stopping to terminate training when validation score is not improving. It automatically sets aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.\n",
    "\n",
    "mlpClf = MLPClassifier(activation= 'relu', solver = 'adam', \n",
    "                       alpha = 0.05, learning_rate = 'invscaling', verbose = True, \n",
    "                       early_stopping = True, max_iter = 400, random_state=0)\n",
    "\n",
    "        \n",
    "# K fold per la cross-validation\n",
    "kfold = KFold(n_splits = 10)\n",
    "\n",
    "# Training and validation on all K folds\n",
    "# for train_indices, test_indices in kf.split(train_data_subreddits):\n",
    "#    mlpClf.fit(train_data_subreddits[train_indices], y[train_indices])\n",
    "#    print(mlpClf.score(train_data_subreddits[test_indices], y[test_indices]))\n",
    "    \n",
    "# cross_val_score resets parameters of my_model and fits it on X_train and t_train with cross validation (we did it for consistency).\n",
    "# results = cross_val_score(my_model, s, y, cv=kfold, scoring='roc_auc')\n",
    "# print(\"roc = \", np.mean(results))\n",
    "    \n",
    "# Model fit\n",
    "mlpClf.fit(train_data_subreddits, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_test = []\n",
    "for author, group in test_data.groupby(\"author\"):\n",
    "    Xs_test.append(group.subreddit.str.cat(sep = \" \"))\n",
    "    \n",
    "clean_test_subreddits = [xs.lower() for xs in Xs_test]\n",
    "\n",
    "test_data_subreddits = vectorizer_.transform(clean_test_subreddits).toarray()\n",
    "\n",
    "y_score = mlpClf.predict_proba(test_data_subreddits)[:,1]\n",
    "\n",
    "np.save(\"y_testMLPs\",y_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
